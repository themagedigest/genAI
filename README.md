This is the model where an image content can be showcased as an audio. Below 2 models have been merged and I believe they may have many useful applications mostly to specially-abled people.

Credits and model used :
1. Image caption capture model - https://huggingface.co/Salesforce/blip-image-captioning-base

   @misc{https://doi.org/10.48550/arxiv.2201.12086,
    doi = {10.48550/ARXIV.2201.12086},
    
    url = {https://arxiv.org/abs/2201.12086},
    
    author = {Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
    
    keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    
    title = {BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
    
    publisher = {arXiv},
    
    year = {2022},
    
    copyright = {Creative Commons Attribution 4.0 International}
}


2. Text to speech model - https://huggingface.co/facebook/mms-tts-eng

   @article{pratap2023mms,
    title={Scaling Speech Technology to 1,000+ Languages},
    author={Vineel Pratap and Andros Tjandra and Bowen Shi and Paden Tomasello and Arun Babu and Sayani Kundu and Ali Elkahky and Zhaoheng Ni and Apoorv Vyas and Maryam Fazel-Zarandi and Alexei Baevski and Yossi Adi and Xiaohui Zhang and Wei-Ning Hsu and Alexis Conneau and Michael Auli},
    journal={arXiv},
    year={2023}
}

   
